import torch
import torch.nn as nn
from utils.logs.log_utils import debug, info


class LSTM(nn.Module):

    def _set_fields(
            self,
            params,
            config_settings
    ):
        """
        Method to set the model's parameters.
        :param params: The model's parameters.
        :param config_settings: The configuration settings.
        :return:
        """
        # initial message
        info("游댃 LSTM fields setting started...")

        # definition of the required parameters
        self.required_parameters = [
            "hidden_size",
            "num_layers",
            "bias",
            "batch_first",
            "dropout",
            "bidirectional",
            "proj_size"
        ]

        try:
            # for each required parameter
            for param in self.required_parameters:
                # check if it is passed to the model
                if (
                    param in params and
                    params[param] is not None
                ):
                    debug(f"丘뙖잺 '{param}' found. Using the specified value ({params[param]}).")
                    # set the parameter to the specified value
                    setattr(
                        self,
                        param,
                        params[param]
                    )
                else:
                    # otherwise, take the parameter from configuration settings
                    config_value = getattr(
                        config_settings,
                        param
                    )
                    debug(f"丘뙖잺 '{param}' not found or is None. Using config value ({config_value}).")
                    # and set the parameter to that value
                    setattr(
                        self,
                        param,
                        config_value
                    )

            # apply dropout only if num_layers > 1
            if self.num_layers > 1:
                self.dropout = float(self.dropout)
                debug(f"丘뙖잺 'dropout' applied: {self.dropout}")
            else:
                debug(f"丘뙖잺 'dropout' cannot be applied with num_layers = {self.num_layers}.")
                self.dropout = 0.0

            # set the no. of keys
            self.num_keys = config_settings.num_keys

            # apply embedding
            self.embedding_dim = config_settings.embedding_dim

            # instantiate the embedding layer
            self.embedding = nn.Embedding(
                self.num_keys,
                self.embedding_dim
            )
        except AttributeError as e:
            raise AttributeError(f"AttributeError: {e}.")
        except KeyError as e:
            raise KeyError(f"KeyError: {e}.")
        except TypeError as e:
            raise TypeError(f"TypeError: {e}.")
        except ValueError as e:
            raise ValueError(f"ValueError: {e}.")
        except Exception as e:
            raise RuntimeError(f"RuntimeError: {e}.")

        # show a successful message
        info("游릭 LSTM fields set.")


    def __init__(
            self,
            params,
            config_settings
    ):
        """
        Method to initialize the LSTM model.
        :param params: The hyperparameters of the model.
        :param config_settings: The configuration settings.
        """
        # initial message
        info("游댃 LSTM initialization started...")

        super(LSTM, self).__init__()

        # by default
        self.use_mc_dropout = False

        # set model's parameters
        self._set_fields(
            params,
            config_settings
        )

        # debugging
        for param in self.required_parameters:
            debug(f"丘뙖잺 {param} = {getattr(self, param)}.")

        try:
            # instantiate the LSTM model
            self.lstm = nn.LSTM(
                input_size=config_settings.num_features
                +self.embedding_dim,
                hidden_size=self.hidden_size,
                num_layers=self.num_layers,
                bias=self.bias,
                batch_first=self.batch_first,
                dropout=self.dropout,
                bidirectional=self.bidirectional,
                proj_size=self.proj_size
            )
        except TypeError as e:
            raise TypeError(f"TypeError: {e}.")
        except ValueError as e:
            raise ValueError(f"ValueError: {e}.")
        except KeyError as e:
            raise KeyError(f"KeyError: {e}.")
        except Exception as e:
            raise RuntimeError(f"RuntimeError: {e}.")

        try:
            self.mc_dropout_layer = nn.Dropout(
                p=self.dropout
            )
        except TypeError as e:
            raise TypeError(f"TypeError: {e}.")
        except AttributeError as e:
            raise AttributeError(f"AttributeError: {e}.")
        except Exception as e:
            raise RuntimeError(f"RuntimeError: {e}.")

        try:
            # fully-connected layer (linear)
            self.fc = nn.Linear(
                self.hidden_size,
                self.num_keys
            )
        except TypeError as e:
            raise TypeError(f"TypeError: {e}.")
        except ValueError as e:
            raise ValueError(f"ValueError: {e}.")
        except Exception as e:
            raise RuntimeError(f"RuntimeError: {e}.")

        # show a successful message
        info("游릭 LSTM initialized.")


    def _get_lstm_input(
            self,
            x_features,
            x_keys
    ):
        """
        Method to prepare and return the LSTM input.
        :param x_features: The features to pass to the model.
        :param x_keys: The keys to embed and pass to the model.
        :return: The LSTM input.
        """
        # initial message
        info("游댃 LSTM input retrieval started...")

        # check the inputs validity
        if (
            x_features is None or
            x_keys is None
        ):
            raise ValueError("Input features cannot be None.")

        # debugging
        debug(f"丘뙖잺 Input features shape: {x_features.shape}.")
        debug(f"丘뙖잺 Input keys shape: {x_keys.shape}.")

        # pass the key through the embedding layer
        embedded_keys = self.embedding(x_keys)

        # debugging
        debug(f"丘뙖잺 Embedded keys shape: {embedded_keys.shape}.")

        try:
            # concatenate embedding layer with the other features
            x = torch.cat(
                (x_features, embedded_keys),
                dim=-1
            )
        except RuntimeError as e:
            raise RuntimeError(f"RuntimeError: {e}.")
        except TypeError as e:
            raise TypeError(f"TypeError: {e}.")
        except Exception as e:
            raise RuntimeError(f"RuntimeError: {e}.")

        # show a successful message
        info("游릭 LSTM input retrieved.")

        return x


    def forward(
            self,
            x_features,
            x_keys
    ):
        """
        Method to perform the forward pass through the LSTM.
        :param x_features: The features.
        :param x_keys: The keys.
        :return: The logits of the LSTM.
        """
        # initial message
        info("游댃 LSTM forward started...")

        try:
            # get the input of the LSTM
            x = self._get_lstm_input(
                x_features,
                x_keys
            )

            # pass the features to the LSTM
            lstm_out, _ = self.lstm(x)

            # check if using dropout
            if self.use_mc_dropout:
                lstm_out = self.mc_dropout_layer(lstm_out)
        except AttributeError as e:
            raise AttributeError(f"AttributeError: {e}.")
        except TypeError as e:
            raise TypeError(f"TypeError: {e}.")
        except ValueError as e:
            raise ValueError(f"ValueError: {e}.")
        except Exception as e:
            raise RuntimeError(f"RuntimeError: {e}.")

        # debugging
        debug(f"丘뙖잺 Output shape: {lstm_out.shape}.")

        try:
            # get the logits from the LSTM output
            logits = self.fc(lstm_out[:, -1, :])
        except IndexError as e:
            raise IndexError(f"IndexError: {e}.")
        except AttributeError as e:
            raise AttributeError(f"AttributeError: {e}.")
        except Exception as e:
            raise RuntimeError(f"RuntimeError: {e}.")

        # debugging
        debug(f"丘뙖잺 Logits shape: {logits.shape}.")

        # show a successful message
        info("游릭 LSTM forward completed.")

        return logits