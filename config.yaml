model:
  hidden_size: 128
  num_layers: 2
  bias: True
  batch_first: True
  dropout: 0.3
  bidirectional: False
  proj_size: 0
  embedding_dim: 256

training:
  epochs: 5
  batch_size: 64
  learning_rate: 0.001
  model_save_path: "../model/trained_lstm_model.pt"

data:
  n_requests: 50000
  n_keys: 1000
  alpha: 1.3
  alpha_start: 1.3
  alpha_end: 1.8
  time_steps: 100
  static_dataset_path: "../data/static_access_logs.csv"
  dynamic_dataset_path: "../data/dynamic_access_logs.csv"
